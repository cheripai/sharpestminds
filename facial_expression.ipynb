{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Expression Recognition Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge\n",
    "\n",
    "From Kaggle:\n",
    "\n",
    "The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
    "\n",
    "The training set consists of 28,709 examples. The public test set used for the leaderboard consists of 3,589 examples. The final test set, which was used to determine the winner of the competition, consists of another 3,589 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Kaggle provides us with two test sets, we make the public test set our validation set and the private test set our test set. \n",
    "\n",
    "This does provide us with more training data as we don't have to partition a validation set out of our training set, so it does give us a slight advantage over the leaderboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from imageio import imwrite\n",
    "\n",
    "TRAIN_PATH = \"data/train\"\n",
    "VALID_PATH = \"data/valid\"\n",
    "TEST_PATH = \"data/test\"\n",
    "DATASET_PATHS = (TRAIN_PATH, VALID_PATH, TEST_PATH)\n",
    "\n",
    "OUTPUTS = 7\n",
    "IMG_SIZE = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert csv file to images and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for train, valid, and test\n",
    "for dataset_path in DATASET_PATHS:\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.mkdir(dataset_path)\n",
    "\n",
    "    # Make a directory for each emotion\n",
    "    for target in df[\"emotion\"].unique():\n",
    "        path_target = os.path.join(dataset_path, str(target))\n",
    "        if not os.path.exists(path_target):\n",
    "            os.mkdir(os.path.join(path_target))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    # Convert image to numpy array and reshape to be 2d\n",
    "    img = np.array(list(map(int, row[\"pixels\"].split(\" \"))))\n",
    "    img = img.reshape((IMG_SIZE, IMG_SIZE)).astype(np.uint8)\n",
    "\n",
    "    # File name is <number>.png\n",
    "    fname = str(i)+\".png\"\n",
    "\n",
    "    if row[\"Usage\"] == \"Training\":\n",
    "        path = os.path.join(TRAIN_PATH, str(row[\"emotion\"]))\n",
    "    elif row[\"Usage\"] == \"PublicTest\":\n",
    "        path = os.path.join(VALID_PATH, str(row[\"emotion\"]))\n",
    "    elif row[\"Usage\"] == \"PrivateTest\":\n",
    "        path = os.path.join(TEST_PATH, str(row[\"emotion\"]))\n",
    "    else:\n",
    "        raise Exception(\"Invalid Usage: {}\".format(row[\"Usage\"]))\n",
    "        \n",
    "    imwrite(os.path.join(path, fname), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build functions for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def transfer_CNN(base, outputs, lr=0.0005, dropout=0.5, decay=0.001):\n",
    "    \"\"\" Appends a series of dense layers to any pretrained network and compiles for transfer learning.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        base,\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(input_shape=base.output_shape[1:]),\n",
    "        Dropout(dropout),\n",
    "        Dense(1024, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout),\n",
    "        Dense(1024, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout),\n",
    "        Dense(outputs, activation=\"softmax\"),\n",
    "    ])\n",
    "    opt = Adam(lr=lr, decay=decay)\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create ImageDataGenerator for data augmentation\n",
    "# Rescale image to be between 0 and 1\n",
    "# Allow horizontal flipping, x&y shifting, and zooming\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.10,\n",
    "    height_shift_range=0.10,\n",
    "    zoom_range=0.10)\n",
    "\n",
    "# Rescale validation and test images to be between 0 and 1\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "IN_IMG_SIZE = 200\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"data/train\",\n",
    "    target_size=(IN_IMG_SIZE, IN_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    \"data/valid\",\n",
    "    target_size=(IN_IMG_SIZE, IN_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "def train(cnn, model_name, epochs=EPOCHS, batch_size=BATCH_SIZE):\n",
    "    print(\"Training {}\".format(model_name))\n",
    "    \n",
    "    callbacks = [\n",
    "        TensorBoard(), \n",
    "        ModelCheckpoint(\"data/{}.h5\".format(model_name), monitor=\"val_acc\", save_best_only=True, save_weights_only=True),\n",
    "        EarlyStopping(monitor=\"val_acc\", patience=10)\n",
    "    ]\n",
    "    \n",
    "    cnn.model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // batch_size + 1,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.n // batch_size + 1,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform transfer learning on 4 state-of-the-art models from Keras applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training InceptionResNetV2\n",
      "Epoch 1/50\n",
      "898/898 [==============================] - 461s 513ms/step - loss: 2.3416 - acc: 0.3059 - val_loss: 1.4345 - val_acc: 0.4723\n",
      "Epoch 2/50\n",
      "898/898 [==============================] - 451s 503ms/step - loss: 1.7153 - acc: 0.4280 - val_loss: 1.2717 - val_acc: 0.5132\n",
      "Epoch 3/50\n",
      "898/898 [==============================] - 453s 504ms/step - loss: 1.5050 - acc: 0.4759 - val_loss: 1.2260 - val_acc: 0.5534\n",
      "Epoch 4/50\n",
      "898/898 [==============================] - 453s 504ms/step - loss: 1.3678 - acc: 0.5126 - val_loss: 1.1621 - val_acc: 0.5634\n",
      "Epoch 5/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 1.2660 - acc: 0.5445 - val_loss: 1.1112 - val_acc: 0.5876\n",
      "Epoch 6/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 1.1936 - acc: 0.5672 - val_loss: 1.1038 - val_acc: 0.6004\n",
      "Epoch 7/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 1.1431 - acc: 0.5852 - val_loss: 1.0817 - val_acc: 0.5993\n",
      "Epoch 8/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 1.0813 - acc: 0.6092 - val_loss: 1.0652 - val_acc: 0.6158\n",
      "Epoch 9/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 1.0417 - acc: 0.6218 - val_loss: 1.0434 - val_acc: 0.6308\n",
      "Epoch 10/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 1.0046 - acc: 0.6343 - val_loss: 1.0107 - val_acc: 0.6333\n",
      "Epoch 11/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.9608 - acc: 0.6537 - val_loss: 1.0258 - val_acc: 0.6347\n",
      "Epoch 12/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.9266 - acc: 0.6682 - val_loss: 1.0269 - val_acc: 0.6436\n",
      "Epoch 13/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.8924 - acc: 0.6781 - val_loss: 1.0291 - val_acc: 0.6445\n",
      "Epoch 14/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.8606 - acc: 0.6894 - val_loss: 1.0142 - val_acc: 0.6481\n",
      "Epoch 15/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.8309 - acc: 0.7025 - val_loss: 0.9903 - val_acc: 0.6556\n",
      "Epoch 16/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.8028 - acc: 0.7166 - val_loss: 0.9924 - val_acc: 0.6567\n",
      "Epoch 17/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.7763 - acc: 0.7221 - val_loss: 1.0028 - val_acc: 0.6520\n",
      "Epoch 18/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.7553 - acc: 0.7286 - val_loss: 1.0105 - val_acc: 0.6548\n",
      "Epoch 19/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.7172 - acc: 0.7433 - val_loss: 1.0136 - val_acc: 0.6573\n",
      "Epoch 20/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.7128 - acc: 0.7470 - val_loss: 1.0018 - val_acc: 0.6500\n",
      "Epoch 21/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.6819 - acc: 0.7600 - val_loss: 1.0060 - val_acc: 0.6534\n",
      "Epoch 22/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.6709 - acc: 0.7622 - val_loss: 1.0111 - val_acc: 0.6590\n",
      "Epoch 23/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.6430 - acc: 0.7724 - val_loss: 1.0346 - val_acc: 0.6565\n",
      "Epoch 24/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.6320 - acc: 0.7780 - val_loss: 1.0266 - val_acc: 0.6573\n",
      "Epoch 25/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.6117 - acc: 0.7863 - val_loss: 1.0388 - val_acc: 0.6595\n",
      "Epoch 26/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.5947 - acc: 0.7917 - val_loss: 1.0358 - val_acc: 0.6576\n",
      "Epoch 27/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.5866 - acc: 0.7943 - val_loss: 1.0489 - val_acc: 0.6615\n",
      "Epoch 28/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.5713 - acc: 0.7978 - val_loss: 1.0379 - val_acc: 0.6578\n",
      "Epoch 29/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.5592 - acc: 0.8040 - val_loss: 1.0493 - val_acc: 0.6587\n",
      "Epoch 30/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.5498 - acc: 0.8069 - val_loss: 1.0610 - val_acc: 0.6626\n",
      "Epoch 31/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.5286 - acc: 0.8133 - val_loss: 1.0611 - val_acc: 0.6634\n",
      "Epoch 32/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.5191 - acc: 0.8192 - val_loss: 1.0743 - val_acc: 0.6615\n",
      "Epoch 33/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.4978 - acc: 0.8274 - val_loss: 1.0801 - val_acc: 0.6592\n",
      "Epoch 34/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.4940 - acc: 0.8250 - val_loss: 1.0886 - val_acc: 0.6629\n",
      "Epoch 35/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.4854 - acc: 0.8300 - val_loss: 1.0679 - val_acc: 0.6595\n",
      "Epoch 36/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.4781 - acc: 0.8346 - val_loss: 1.0962 - val_acc: 0.6634\n",
      "Epoch 37/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.4559 - acc: 0.8417 - val_loss: 1.0932 - val_acc: 0.6573\n",
      "Epoch 38/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.4443 - acc: 0.8464 - val_loss: 1.1013 - val_acc: 0.6620\n",
      "Epoch 39/50\n",
      "898/898 [==============================] - 452s 503ms/step - loss: 0.4431 - acc: 0.8434 - val_loss: 1.1107 - val_acc: 0.6609\n",
      "Epoch 40/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.4335 - acc: 0.8468 - val_loss: 1.1091 - val_acc: 0.6609\n",
      "Epoch 41/50\n",
      "898/898 [==============================] - 452s 504ms/step - loss: 0.4241 - acc: 0.8523 - val_loss: 1.1303 - val_acc: 0.6601\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "base = InceptionResNetV2(include_top=False, weights=\"imagenet\")\n",
    "model = transfer_CNN(base, OUTPUTS, lr=0.0001)\n",
    "train(model, \"InceptionResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG\n",
      "Epoch 1/50\n",
      "898/898 [==============================] - 398s 444ms/step - loss: 2.4281 - acc: 0.1914 - val_loss: 1.8139 - val_acc: 0.2402\n",
      "Epoch 2/50\n",
      "898/898 [==============================] - 392s 437ms/step - loss: 2.0583 - acc: 0.2108 - val_loss: 4.5340 - val_acc: 0.1184\n",
      "Epoch 3/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.9482 - acc: 0.2278 - val_loss: 5.4302 - val_acc: 0.1819\n",
      "Epoch 4/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.8598 - acc: 0.2508 - val_loss: 3.2674 - val_acc: 0.1819\n",
      "Epoch 5/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.8316 - acc: 0.2557 - val_loss: 1.7283 - val_acc: 0.3112\n",
      "Epoch 6/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.7565 - acc: 0.2820 - val_loss: 1.6796 - val_acc: 0.3040\n",
      "Epoch 7/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.7191 - acc: 0.2984 - val_loss: 1.7211 - val_acc: 0.2705\n",
      "Epoch 8/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.6544 - acc: 0.3341 - val_loss: 1.8674 - val_acc: 0.2842\n",
      "Epoch 9/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.5101 - acc: 0.4014 - val_loss: 1.5729 - val_acc: 0.3533\n",
      "Epoch 10/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.3987 - acc: 0.4547 - val_loss: 1.3878 - val_acc: 0.4631\n",
      "Epoch 11/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.3215 - acc: 0.4907 - val_loss: 1.2949 - val_acc: 0.4937\n",
      "Epoch 12/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.2621 - acc: 0.5166 - val_loss: 1.4297 - val_acc: 0.4285\n",
      "Epoch 13/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.2086 - acc: 0.5354 - val_loss: 1.1350 - val_acc: 0.5578\n",
      "Epoch 14/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.1703 - acc: 0.5511 - val_loss: 1.3680 - val_acc: 0.4809\n",
      "Epoch 15/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.1383 - acc: 0.5655 - val_loss: 1.1050 - val_acc: 0.5759\n",
      "Epoch 16/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 1.1133 - acc: 0.5799 - val_loss: 1.1870 - val_acc: 0.5336\n",
      "Epoch 17/50\n",
      "898/898 [==============================] - 394s 438ms/step - loss: 1.0764 - acc: 0.5935 - val_loss: 1.0785 - val_acc: 0.5885\n",
      "Epoch 18/50\n",
      "898/898 [==============================] - 394s 439ms/step - loss: 1.0472 - acc: 0.6068 - val_loss: 1.0868 - val_acc: 0.5823\n",
      "Epoch 19/50\n",
      "898/898 [==============================] - 394s 438ms/step - loss: 1.0116 - acc: 0.6202 - val_loss: 1.0622 - val_acc: 0.5879\n",
      "Epoch 20/50\n",
      "898/898 [==============================] - 394s 438ms/step - loss: 0.9866 - acc: 0.6305 - val_loss: 1.0388 - val_acc: 0.6030\n",
      "Epoch 21/50\n",
      "898/898 [==============================] - 394s 438ms/step - loss: 0.9652 - acc: 0.6379 - val_loss: 1.0663 - val_acc: 0.6091\n",
      "Epoch 22/50\n",
      "898/898 [==============================] - 394s 438ms/step - loss: 0.9315 - acc: 0.6528 - val_loss: 1.0740 - val_acc: 0.5993\n",
      "Epoch 23/50\n",
      "898/898 [==============================] - 394s 438ms/step - loss: 0.9149 - acc: 0.6617 - val_loss: 1.0098 - val_acc: 0.6160\n",
      "Epoch 24/50\n",
      "898/898 [==============================] - 394s 439ms/step - loss: 0.8910 - acc: 0.6683 - val_loss: 1.1774 - val_acc: 0.5570\n",
      "Epoch 25/50\n",
      "898/898 [==============================] - 394s 439ms/step - loss: 0.8627 - acc: 0.6819 - val_loss: 1.0244 - val_acc: 0.6113\n",
      "Epoch 26/50\n",
      "898/898 [==============================] - 394s 439ms/step - loss: 0.8387 - acc: 0.6913 - val_loss: 1.0205 - val_acc: 0.6289\n",
      "Epoch 27/50\n",
      "898/898 [==============================] - 394s 439ms/step - loss: 0.8130 - acc: 0.7011 - val_loss: 0.9930 - val_acc: 0.6383\n",
      "Epoch 28/50\n",
      "898/898 [==============================] - 394s 439ms/step - loss: 0.7921 - acc: 0.7086 - val_loss: 1.1428 - val_acc: 0.5940\n",
      "Epoch 29/50\n",
      "898/898 [==============================] - 395s 440ms/step - loss: 0.7620 - acc: 0.7222 - val_loss: 1.0789 - val_acc: 0.6105\n",
      "Epoch 30/50\n",
      "898/898 [==============================] - 395s 440ms/step - loss: 0.7315 - acc: 0.7315 - val_loss: 1.0090 - val_acc: 0.6381\n",
      "Epoch 31/50\n",
      "898/898 [==============================] - 395s 440ms/step - loss: 0.7107 - acc: 0.7383 - val_loss: 1.0679 - val_acc: 0.6272\n",
      "Epoch 32/50\n",
      "898/898 [==============================] - 395s 440ms/step - loss: 0.6903 - acc: 0.7474 - val_loss: 1.1607 - val_acc: 0.5887\n",
      "Epoch 33/50\n",
      "898/898 [==============================] - 395s 440ms/step - loss: 0.6597 - acc: 0.7591 - val_loss: 1.0406 - val_acc: 0.6459\n",
      "Epoch 34/50\n",
      "898/898 [==============================] - 395s 440ms/step - loss: 0.6430 - acc: 0.7684 - val_loss: 1.0748 - val_acc: 0.6381\n",
      "Epoch 35/50\n",
      "898/898 [==============================] - 395s 440ms/step - loss: 0.6112 - acc: 0.7796 - val_loss: 1.1293 - val_acc: 0.6339\n",
      "Epoch 36/50\n",
      "898/898 [==============================] - 393s 437ms/step - loss: 0.5916 - acc: 0.7871 - val_loss: 1.1137 - val_acc: 0.6470\n",
      "Epoch 37/50\n",
      "898/898 [==============================] - 393s 437ms/step - loss: 0.5641 - acc: 0.7995 - val_loss: 1.0886 - val_acc: 0.6500\n",
      "Epoch 38/50\n",
      "898/898 [==============================] - 392s 437ms/step - loss: 0.5403 - acc: 0.8095 - val_loss: 1.2244 - val_acc: 0.6158\n",
      "Epoch 39/50\n",
      "898/898 [==============================] - 392s 437ms/step - loss: 0.5160 - acc: 0.8167 - val_loss: 1.2159 - val_acc: 0.6236\n",
      "Epoch 40/50\n",
      "898/898 [==============================] - 393s 437ms/step - loss: 0.4924 - acc: 0.8263 - val_loss: 1.1751 - val_acc: 0.6484\n",
      "Epoch 41/50\n",
      "898/898 [==============================] - 396s 441ms/step - loss: 0.4692 - acc: 0.8359 - val_loss: 1.2868 - val_acc: 0.6188\n",
      "Epoch 42/50\n",
      "898/898 [==============================] - 408s 454ms/step - loss: 0.4614 - acc: 0.8358 - val_loss: 1.1966 - val_acc: 0.6626\n",
      "Epoch 43/50\n",
      "898/898 [==============================] - 393s 438ms/step - loss: 0.4330 - acc: 0.8486 - val_loss: 1.2611 - val_acc: 0.6428\n",
      "Epoch 44/50\n",
      "898/898 [==============================] - 400s 446ms/step - loss: 0.4164 - acc: 0.8529 - val_loss: 1.6772 - val_acc: 0.5946\n",
      "Epoch 45/50\n",
      "898/898 [==============================] - 405s 450ms/step - loss: 0.3964 - acc: 0.8617 - val_loss: 1.2318 - val_acc: 0.6648\n",
      "Epoch 46/50\n",
      "898/898 [==============================] - 398s 444ms/step - loss: 0.3713 - acc: 0.8709 - val_loss: 1.3784 - val_acc: 0.6339\n",
      "Epoch 47/50\n",
      "898/898 [==============================] - 404s 450ms/step - loss: 0.3656 - acc: 0.8717 - val_loss: 1.3520 - val_acc: 0.6545\n",
      "Epoch 48/50\n",
      "898/898 [==============================] - 405s 451ms/step - loss: 0.3435 - acc: 0.8833 - val_loss: 1.4295 - val_acc: 0.6300\n",
      "Epoch 49/50\n",
      "898/898 [==============================] - 411s 457ms/step - loss: 0.3201 - acc: 0.8888 - val_loss: 1.4831 - val_acc: 0.6269\n",
      "Epoch 50/50\n",
      "898/898 [==============================] - 420s 468ms/step - loss: 0.3090 - acc: 0.8943 - val_loss: 1.4383 - val_acc: 0.6330\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "base = VGG16(include_top=False, weights=\"imagenet\")\n",
    "model = transfer_CNN(base, OUTPUTS)\n",
    "train(model, \"VGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet\n",
      "Epoch 1/50\n",
      "898/898 [==============================] - 355s 396ms/step - loss: 1.8232 - acc: 0.4056 - val_loss: 1.2349 - val_acc: 0.5255\n",
      "Epoch 2/50\n",
      "898/898 [==============================] - 352s 392ms/step - loss: 1.2821 - acc: 0.5284 - val_loss: 1.1215 - val_acc: 0.5748\n",
      "Epoch 3/50\n",
      "898/898 [==============================] - 353s 393ms/step - loss: 1.1407 - acc: 0.5796 - val_loss: 1.0575 - val_acc: 0.6007\n",
      "Epoch 4/50\n",
      "898/898 [==============================] - 346s 385ms/step - loss: 1.0843 - acc: 0.5994 - val_loss: 1.0672 - val_acc: 0.5999\n",
      "Epoch 5/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 1.0377 - acc: 0.6187 - val_loss: 1.0703 - val_acc: 0.5988\n",
      "Epoch 6/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.9711 - acc: 0.6446 - val_loss: 0.9613 - val_acc: 0.6484\n",
      "Epoch 7/50\n",
      "898/898 [==============================] - 344s 384ms/step - loss: 0.9463 - acc: 0.6571 - val_loss: 0.9467 - val_acc: 0.6464\n",
      "Epoch 8/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.8913 - acc: 0.6738 - val_loss: 0.9517 - val_acc: 0.6559\n",
      "Epoch 9/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.8583 - acc: 0.6853 - val_loss: 0.9844 - val_acc: 0.6397\n",
      "Epoch 10/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.8166 - acc: 0.7005 - val_loss: 0.9010 - val_acc: 0.6673\n",
      "Epoch 11/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.7738 - acc: 0.7181 - val_loss: 0.9073 - val_acc: 0.6754\n",
      "Epoch 12/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.7426 - acc: 0.7293 - val_loss: 0.9199 - val_acc: 0.6670\n",
      "Epoch 13/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.7086 - acc: 0.7460 - val_loss: 0.9162 - val_acc: 0.6682\n",
      "Epoch 14/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.6807 - acc: 0.7548 - val_loss: 0.9059 - val_acc: 0.6709\n",
      "Epoch 15/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.6534 - acc: 0.7659 - val_loss: 0.9102 - val_acc: 0.6799\n",
      "Epoch 16/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.6133 - acc: 0.7809 - val_loss: 0.9447 - val_acc: 0.6707\n",
      "Epoch 17/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.5998 - acc: 0.7848 - val_loss: 0.9100 - val_acc: 0.6818\n",
      "Epoch 18/50\n",
      "898/898 [==============================] - 345s 384ms/step - loss: 0.5636 - acc: 0.7977 - val_loss: 0.9219 - val_acc: 0.6818\n",
      "Epoch 19/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.5299 - acc: 0.8124 - val_loss: 0.9419 - val_acc: 0.6896\n",
      "Epoch 20/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.5021 - acc: 0.8232 - val_loss: 0.9977 - val_acc: 0.6768\n",
      "Epoch 21/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.4895 - acc: 0.8304 - val_loss: 1.0019 - val_acc: 0.6765\n",
      "Epoch 22/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.4594 - acc: 0.8417 - val_loss: 1.0092 - val_acc: 0.6882\n",
      "Epoch 23/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.4339 - acc: 0.8506 - val_loss: 1.0124 - val_acc: 0.6893\n",
      "Epoch 24/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.4098 - acc: 0.8590 - val_loss: 1.0427 - val_acc: 0.6804\n",
      "Epoch 25/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.3946 - acc: 0.8643 - val_loss: 1.0474 - val_acc: 0.6868\n",
      "Epoch 26/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.3699 - acc: 0.8720 - val_loss: 1.0896 - val_acc: 0.6843\n",
      "Epoch 27/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.3690 - acc: 0.8721 - val_loss: 1.1014 - val_acc: 0.6854\n",
      "Epoch 28/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.3402 - acc: 0.8849 - val_loss: 1.0962 - val_acc: 0.6938\n",
      "Epoch 29/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.3207 - acc: 0.8902 - val_loss: 1.1113 - val_acc: 0.6877\n",
      "Epoch 30/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.2987 - acc: 0.8975 - val_loss: 1.1646 - val_acc: 0.6757\n",
      "Epoch 31/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.2907 - acc: 0.8994 - val_loss: 1.1638 - val_acc: 0.6857\n",
      "Epoch 32/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.2833 - acc: 0.9053 - val_loss: 1.1564 - val_acc: 0.6918\n",
      "Epoch 33/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.2707 - acc: 0.9075 - val_loss: 1.1668 - val_acc: 0.6860\n",
      "Epoch 34/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.2537 - acc: 0.9132 - val_loss: 1.2059 - val_acc: 0.6851\n",
      "Epoch 35/50\n",
      "898/898 [==============================] - 344s 383ms/step - loss: 0.2458 - acc: 0.9139 - val_loss: 1.2130 - val_acc: 0.6910\n",
      "Epoch 36/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.2394 - acc: 0.9170 - val_loss: 1.1982 - val_acc: 0.6952\n",
      "Epoch 37/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.2299 - acc: 0.9209 - val_loss: 1.2283 - val_acc: 0.6957\n",
      "Epoch 38/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.2082 - acc: 0.9281 - val_loss: 1.2753 - val_acc: 0.6938\n",
      "Epoch 39/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.2118 - acc: 0.9291 - val_loss: 1.2986 - val_acc: 0.6860\n",
      "Epoch 40/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.1950 - acc: 0.9330 - val_loss: 1.2923 - val_acc: 0.6949\n",
      "Epoch 41/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.1919 - acc: 0.9338 - val_loss: 1.3186 - val_acc: 0.6904\n",
      "Epoch 42/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.1870 - acc: 0.9371 - val_loss: 1.3757 - val_acc: 0.6885\n",
      "Epoch 43/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.1799 - acc: 0.9397 - val_loss: 1.3517 - val_acc: 0.6851\n",
      "Epoch 44/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.1684 - acc: 0.9431 - val_loss: 1.3756 - val_acc: 0.6865\n",
      "Epoch 45/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.1705 - acc: 0.9420 - val_loss: 1.3670 - val_acc: 0.6846\n",
      "Epoch 46/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.1593 - acc: 0.9439 - val_loss: 1.3644 - val_acc: 0.6910\n",
      "Epoch 47/50\n",
      "898/898 [==============================] - 343s 382ms/step - loss: 0.1538 - acc: 0.9474 - val_loss: 1.4260 - val_acc: 0.6860\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "\n",
    "base = ResNet50(include_top=False, weights=\"imagenet\")\n",
    "model = transfer_CNN(base, OUTPUTS)\n",
    "train(model, \"ResNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Inception\n",
      "Epoch 1/50\n",
      "898/898 [==============================] - 236s 263ms/step - loss: 2.1634 - acc: 0.3112 - val_loss: 1.4171 - val_acc: 0.4163\n",
      "Epoch 2/50\n",
      "898/898 [==============================] - 244s 272ms/step - loss: 1.6012 - acc: 0.4339 - val_loss: 1.2991 - val_acc: 0.5177\n",
      "Epoch 3/50\n",
      "898/898 [==============================] - 245s 273ms/step - loss: 1.3319 - acc: 0.5127 - val_loss: 1.1104 - val_acc: 0.5851\n",
      "Epoch 4/50\n",
      "898/898 [==============================] - 233s 259ms/step - loss: 1.2166 - acc: 0.5590 - val_loss: 1.1616 - val_acc: 0.5748\n",
      "Epoch 5/50\n",
      "898/898 [==============================] - 233s 259ms/step - loss: 1.1250 - acc: 0.5891 - val_loss: 1.0280 - val_acc: 0.6158\n",
      "Epoch 6/50\n",
      "898/898 [==============================] - 235s 261ms/step - loss: 1.0842 - acc: 0.6071 - val_loss: 0.9887 - val_acc: 0.6291\n",
      "Epoch 7/50\n",
      "898/898 [==============================] - 237s 264ms/step - loss: 1.0197 - acc: 0.6282 - val_loss: 0.9710 - val_acc: 0.6350\n",
      "Epoch 8/50\n",
      "898/898 [==============================] - 238s 265ms/step - loss: 0.9605 - acc: 0.6505 - val_loss: 0.9834 - val_acc: 0.6400\n",
      "Epoch 9/50\n",
      "898/898 [==============================] - 240s 268ms/step - loss: 0.9344 - acc: 0.6613 - val_loss: 0.9376 - val_acc: 0.6514\n",
      "Epoch 10/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.8750 - acc: 0.6843 - val_loss: 0.9416 - val_acc: 0.6509\n",
      "Epoch 11/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.8483 - acc: 0.6930 - val_loss: 0.9315 - val_acc: 0.6598\n",
      "Epoch 12/50\n",
      "898/898 [==============================] - 237s 264ms/step - loss: 0.7946 - acc: 0.7122 - val_loss: 0.9314 - val_acc: 0.6578\n",
      "Epoch 13/50\n",
      "898/898 [==============================] - 237s 264ms/step - loss: 0.7436 - acc: 0.7349 - val_loss: 0.9267 - val_acc: 0.6648\n",
      "Epoch 14/50\n",
      "898/898 [==============================] - 236s 262ms/step - loss: 0.7098 - acc: 0.7452 - val_loss: 0.9315 - val_acc: 0.6682\n",
      "Epoch 15/50\n",
      "898/898 [==============================] - 233s 260ms/step - loss: 0.6700 - acc: 0.7633 - val_loss: 0.9506 - val_acc: 0.6704\n",
      "Epoch 16/50\n",
      "898/898 [==============================] - 234s 260ms/step - loss: 0.6443 - acc: 0.7713 - val_loss: 0.9451 - val_acc: 0.6790\n",
      "Epoch 17/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.6002 - acc: 0.7890 - val_loss: 0.9670 - val_acc: 0.6665\n",
      "Epoch 18/50\n",
      "898/898 [==============================] - 236s 263ms/step - loss: 0.5748 - acc: 0.7980 - val_loss: 0.9626 - val_acc: 0.6854\n",
      "Epoch 19/50\n",
      "898/898 [==============================] - 236s 263ms/step - loss: 0.5272 - acc: 0.8162 - val_loss: 0.9871 - val_acc: 0.6807\n",
      "Epoch 20/50\n",
      "898/898 [==============================] - 236s 263ms/step - loss: 0.4950 - acc: 0.8272 - val_loss: 1.0071 - val_acc: 0.6796\n",
      "Epoch 21/50\n",
      "898/898 [==============================] - 237s 264ms/step - loss: 0.4797 - acc: 0.8321 - val_loss: 0.9854 - val_acc: 0.6824\n",
      "Epoch 22/50\n",
      "898/898 [==============================] - 236s 263ms/step - loss: 0.4610 - acc: 0.8393 - val_loss: 1.0250 - val_acc: 0.6812\n",
      "Epoch 23/50\n",
      "898/898 [==============================] - 235s 262ms/step - loss: 0.4402 - acc: 0.8462 - val_loss: 1.0616 - val_acc: 0.6796\n",
      "Epoch 24/50\n",
      "898/898 [==============================] - 235s 261ms/step - loss: 0.4041 - acc: 0.8583 - val_loss: 1.0743 - val_acc: 0.6854\n",
      "Epoch 25/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.3915 - acc: 0.8636 - val_loss: 1.0690 - val_acc: 0.6801\n",
      "Epoch 26/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.3609 - acc: 0.8716 - val_loss: 1.1254 - val_acc: 0.6801\n",
      "Epoch 27/50\n",
      "898/898 [==============================] - 235s 261ms/step - loss: 0.3561 - acc: 0.8776 - val_loss: 1.1147 - val_acc: 0.6840\n",
      "Epoch 28/50\n",
      "898/898 [==============================] - 235s 261ms/step - loss: 0.3394 - acc: 0.8835 - val_loss: 1.1473 - val_acc: 0.6857\n",
      "Epoch 29/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.3205 - acc: 0.8895 - val_loss: 1.1890 - val_acc: 0.6821\n",
      "Epoch 30/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.3026 - acc: 0.8967 - val_loss: 1.2040 - val_acc: 0.6810\n",
      "Epoch 31/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.2973 - acc: 0.9008 - val_loss: 1.1939 - val_acc: 0.6843\n",
      "Epoch 32/50\n",
      "898/898 [==============================] - 235s 261ms/step - loss: 0.2697 - acc: 0.9082 - val_loss: 1.2236 - val_acc: 0.6835\n",
      "Epoch 33/50\n",
      "898/898 [==============================] - 234s 261ms/step - loss: 0.2688 - acc: 0.9065 - val_loss: 1.2432 - val_acc: 0.6734\n",
      "Epoch 34/50\n",
      "898/898 [==============================] - 235s 261ms/step - loss: 0.2575 - acc: 0.9131 - val_loss: 1.2651 - val_acc: 0.6773\n",
      "Epoch 35/50\n",
      "898/898 [==============================] - 235s 261ms/step - loss: 0.2495 - acc: 0.9145 - val_loss: 1.2615 - val_acc: 0.6854\n",
      "Epoch 36/50\n",
      "898/898 [==============================] - 233s 260ms/step - loss: 0.2338 - acc: 0.9213 - val_loss: 1.2970 - val_acc: 0.6810\n",
      "Epoch 37/50\n",
      "898/898 [==============================] - 234s 260ms/step - loss: 0.2281 - acc: 0.9209 - val_loss: 1.3064 - val_acc: 0.6751\n",
      "Epoch 38/50\n",
      "898/898 [==============================] - 234s 260ms/step - loss: 0.2202 - acc: 0.9256 - val_loss: 1.3444 - val_acc: 0.6768\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "base = InceptionV3(include_top=False, weights=\"imagenet\")\n",
    "model = transfer_CNN(base, OUTPUTS)\n",
    "train(model, \"Inception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ensemble and check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import VGG16\n",
    "\n",
    "base = InceptionResNetV2(include_top=False, weights=\"imagenet\")\n",
    "inception_resnet = transfer_CNN(base, OUTPUTS)\n",
    "inception_resnet.load_weights(\"data/InceptionResNetV2.h5\")\n",
    "\n",
    "base = VGG16(include_top=False, weights=\"imagenet\")\n",
    "vgg = transfer_CNN(base, OUTPUTS)\n",
    "vgg.load_weights(\"data/VGG.h5\")\n",
    "\n",
    "base = ResNet50(include_top=False, weights=\"imagenet\")\n",
    "resnet = transfer_CNN(base, OUTPUTS)\n",
    "resnet.load_weights(\"data/ResNet.h5\")\n",
    "\n",
    "base = InceptionV3(include_top=False, weights=\"imagenet\")\n",
    "inception = transfer_CNN(base, OUTPUTS)\n",
    "inception.load_weights(\"data/Inception.h5\")\n",
    "\n",
    "models = [inception_resnet, vgg, resnet, inception]\n",
    "# Weights for ensemble averaging\n",
    "weights = [0.25, 0.25, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IN_IMG_SIZE = 200\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def predict_ensemble(models, imgs, weights):\n",
    "    \"\"\" Average the predictions of all models to get ensemble prediction.\n",
    "    \"\"\"\n",
    "    batch_size = imgs.shape[0]\n",
    "    # Create empty array for model predictions\n",
    "    predictions = np.zeros((len(models), batch_size, OUTPUTS))\n",
    "    # Predict the class of the image for each model\n",
    "    for i in range(len(models)):\n",
    "        predictions[i] = models[i].predict(imgs)\n",
    "    # Return the weighted average prediction of all models\n",
    "    return np.argmax(np.average(predictions, axis=0, weights=weights), axis=-1).squeeze()\n",
    "\n",
    "\n",
    "def test_models(models, weights, generator, batch_size=BATCH_SIZE):\n",
    "    \"\"\" Print accuracy of models given generator\n",
    "    \"\"\"\n",
    "    predictions = np.zeros(generator.n)\n",
    "    targets = np.zeros(generator.n)\n",
    "\n",
    "    for i, (imgs, target) in enumerate(generator):\n",
    "        if i >= generator.n // batch_size + 1:\n",
    "            break\n",
    "        predictions[i*batch_size:(i+1)*batch_size] = predict_ensemble(models, imgs, weights)\n",
    "        targets[i*batch_size:(i+1)*batch_size] = np.argmax(target, axis=1)\n",
    "        \n",
    "    accuracy = np.mean(targets == predictions)\n",
    "    print(\"Accuracy: {}\".format(round(accuracy, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n",
      "Accuracy: 0.7275\n"
     ]
    }
   ],
   "source": [
    "valid_generator = test_datagen.flow_from_directory(\n",
    "    \"data/valid\",\n",
    "    target_size=(IN_IMG_SIZE, IN_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False)\n",
    "\n",
    "test_models(models, weights, valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n",
      "Accuracy: 0.73781\n"
     ]
    }
   ],
   "source": [
    "valid_generator = test_datagen.flow_from_directory(\n",
    "    \"data/test\",\n",
    "    target_size=(IN_IMG_SIZE, IN_IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False)\n",
    "\n",
    "test_models(models, weights, valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve 72.75% accuracy on the public test set and 73.781% accuracy on the private test set.\n",
    "\n",
    "This exceeds the top score of 69.768% on the public test and 71.161% on the private test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
